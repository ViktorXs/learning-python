{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe: Crawler\n",
    "\n",
    "**Aufgabe:**\n",
    "\n",
    "- Passe den ArticleFetcher so an, dass er die Informationen aus allen Seiten extrahiert\n",
    "\n",
    "Hier nochmal die URL: http://python.beispiel.programmierenlernen.io/index.php\n",
    "\n",
    "**Tipps:**\n",
    "\n",
    "- Schau dir zuerst an, wie du den Button \"Zur nächsten Seite\" ansteuern kannst.\n",
    "- Wie greifst du von Python aus auf das \"href\" - Attribut dieses Buttons zu?\n",
    "- (Optional): Probier ggf. zuerst, nur die Infos der ersten 2 Seiten zu holen. Kannst du darauf aufbauend das Programm verallgemeinern, so dass es alle Seiten einliest?\n",
    "- Du kannst dich daran orientieren, ob es einen \"Zur nächsten Seite\"-Button gibt, oder nicht. Wenn es diesen Button nicht mehr gibt, bist du auf der letzten Seite angelangt. Welcher Schleifentyp bietet sich hier an, wenn du die Schleife erst dann stoppen willst, wenn es den Button nicht mehr gibt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrawledArticle():\n",
    "    def __init__(self, title, emoji, content, image):\n",
    "        self.title = title\n",
    "        self.emoji = emoji\n",
    "        self.content = content\n",
    "        self.image = image\n",
    "        \n",
    "class ArticleFetcher():\n",
    "    def fetch(self):\n",
    "        url = \"http://python.beispiel.programmierenlernen.io/index.php\"\n",
    "        time.sleep(1)\n",
    "        print(url)\n",
    "        r = requests.get(url)\n",
    "        doc = BeautifulSoup(r.text, \"html.parser\")\n",
    "        \n",
    "        articles = []\n",
    "        for card in doc.select(\".card\"):\n",
    "            emoji = card.select_one(\".emoji\").text\n",
    "            content = card.select_one(\".card-text\").text\n",
    "            title = card.select(\".card-title span\")[1].text\n",
    "            image = urljoin(url, card.select_one(\"img\").attrs[\"src\"])\n",
    "\n",
    "            crawled = CrawledArticle(title, emoji, content, image)\n",
    "            articles.append(crawled)\n",
    "        return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://python.beispiel.programmierenlernen.io/index.php\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.CrawledArticle at 0x1a84b309430>,\n",
       " <__main__.CrawledArticle at 0x1a84b3094c0>,\n",
       " <__main__.CrawledArticle at 0x1a84b309340>,\n",
       " <__main__.CrawledArticle at 0x1a84b309520>,\n",
       " <__main__.CrawledArticle at 0x1a84b309580>,\n",
       " <__main__.CrawledArticle at 0x1a84b3095e0>,\n",
       " <__main__.CrawledArticle at 0x1a84b309640>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetcher = ArticleFetcher()\n",
    "fetcher.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
